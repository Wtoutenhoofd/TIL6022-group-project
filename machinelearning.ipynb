{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22a692e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c60e7aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "tomtom = pd.read_parquet(\"tomtom_data.parquet\")\n",
    "vessels = pd.read_parquet(\"vessels_data.parquet\")\n",
    "sensors_location = pd.read_csv(\"sensor-location.xlsx - Sheet1.csv\", )\n",
    "sensors = pd.read_csv(\"sensordata_SAIL2025.csv\", parse_dates=[\"timestamp\"])\n",
    "\n",
    "sensors_location[\"Effectieve breedte\"] = (\n",
    "    sensors_location[\"Effectieve breedte\"]\n",
    "    .astype(str)\n",
    "    .str.replace(\",\", \".\")\n",
    "    .astype(float)\n",
    ")\n",
    "\n",
    "sensors_location[[\"lat\", \"lon\"]] = (\n",
    "    sensors_location[\"Lat/Long\"]\n",
    "    .str.replace(\" \", \"\")   # remove spaces\n",
    "    .str.split(\",\", expand=True)\n",
    "    .astype(float)\n",
    ")\n",
    "\n",
    "sensors_location = sensors_location.rename(columns={\"Objectummer\": \"sensor_id\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7598e2fa",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "time data \"20250820 24:10\" doesn't match format \"%Y%m%d %H:%M\", at position 132. You might want to try:\n    - passing `format` if your strings have a consistent format;\n    - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n    - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      4\u001b[39m weather = weather[~weather[\u001b[33m\"\u001b[39m\u001b[33mDateTime\u001b[39m\u001b[33m\"\u001b[39m].str.contains(\u001b[33m\"\u001b[39m\u001b[33m24:00\u001b[39m\u001b[33m\"\u001b[39m, na=\u001b[38;5;28;01mFalse\u001b[39;00m)]\n\u001b[32m      6\u001b[39m \u001b[38;5;66;03m# Convert DateTime to datetime objects\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m weather[\u001b[33m\"\u001b[39m\u001b[33mDateTime\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto_datetime\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweather\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mDateTime\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m%\u001b[39;49m\u001b[33;43mY\u001b[39;49m\u001b[33;43m%\u001b[39;49m\u001b[33;43mm\u001b[39;49m\u001b[38;5;132;43;01m%d\u001b[39;49;00m\u001b[33;43m \u001b[39;49m\u001b[33;43m%\u001b[39;49m\u001b[33;43mH:\u001b[39;49m\u001b[33;43m%\u001b[39;49m\u001b[33;43mM\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[38;5;66;03m# Round timestamps to the nearest 3 minutes\u001b[39;00m\n\u001b[32m     10\u001b[39m weather[\u001b[33m\"\u001b[39m\u001b[33mRoundedTime\u001b[39m\u001b[33m\"\u001b[39m] = weather[\u001b[33m\"\u001b[39m\u001b[33mDateTime\u001b[39m\u001b[33m\"\u001b[39m].dt.round(\u001b[33m\"\u001b[39m\u001b[33m3min\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Abel Arts\\anaconda3\\envs\\TIL6022-25\\Lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1072\u001b[39m, in \u001b[36mto_datetime\u001b[39m\u001b[34m(arg, errors, dayfirst, yearfirst, utc, format, exact, unit, infer_datetime_format, origin, cache)\u001b[39m\n\u001b[32m   1070\u001b[39m         result = arg.map(cache_array)\n\u001b[32m   1071\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1072\u001b[39m         values = \u001b[43mconvert_listlike\u001b[49m\u001b[43m(\u001b[49m\u001b[43marg\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_values\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m   1073\u001b[39m         result = arg._constructor(values, index=arg.index, name=arg.name)\n\u001b[32m   1074\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arg, (ABCDataFrame, abc.MutableMapping)):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Abel Arts\\anaconda3\\envs\\TIL6022-25\\Lib\\site-packages\\pandas\\core\\tools\\datetimes.py:435\u001b[39m, in \u001b[36m_convert_listlike_datetimes\u001b[39m\u001b[34m(arg, format, name, utc, unit, errors, dayfirst, yearfirst, exact)\u001b[39m\n\u001b[32m    433\u001b[39m \u001b[38;5;66;03m# `format` could be inferred, or user didn't ask for mixed-format parsing.\u001b[39;00m\n\u001b[32m    434\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mformat\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mformat\u001b[39m != \u001b[33m\"\u001b[39m\u001b[33mmixed\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m435\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_array_strptime_with_fallback\u001b[49m\u001b[43m(\u001b[49m\u001b[43marg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mutc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexact\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    437\u001b[39m result, tz_parsed = objects_to_datetime64(\n\u001b[32m    438\u001b[39m     arg,\n\u001b[32m    439\u001b[39m     dayfirst=dayfirst,\n\u001b[32m   (...)\u001b[39m\u001b[32m    443\u001b[39m     allow_object=\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m    444\u001b[39m )\n\u001b[32m    446\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m tz_parsed \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    447\u001b[39m     \u001b[38;5;66;03m# We can take a shortcut since the datetime64 numpy array\u001b[39;00m\n\u001b[32m    448\u001b[39m     \u001b[38;5;66;03m# is in UTC\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Abel Arts\\anaconda3\\envs\\TIL6022-25\\Lib\\site-packages\\pandas\\core\\tools\\datetimes.py:469\u001b[39m, in \u001b[36m_array_strptime_with_fallback\u001b[39m\u001b[34m(arg, name, utc, fmt, exact, errors)\u001b[39m\n\u001b[32m    458\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_array_strptime_with_fallback\u001b[39m(\n\u001b[32m    459\u001b[39m     arg,\n\u001b[32m    460\u001b[39m     name,\n\u001b[32m   (...)\u001b[39m\u001b[32m    464\u001b[39m     errors: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m    465\u001b[39m ) -> Index:\n\u001b[32m    466\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    467\u001b[39m \u001b[33;03m    Call array_strptime, with fallback behavior depending on 'errors'.\u001b[39;00m\n\u001b[32m    468\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m469\u001b[39m     result, tz_out = \u001b[43marray_strptime\u001b[49m\u001b[43m(\u001b[49m\u001b[43marg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfmt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexact\u001b[49m\u001b[43m=\u001b[49m\u001b[43mexact\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mutc\u001b[49m\u001b[43m=\u001b[49m\u001b[43mutc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    470\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m tz_out \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    471\u001b[39m         unit = np.datetime_data(result.dtype)[\u001b[32m0\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/tslibs/strptime.pyx:501\u001b[39m, in \u001b[36mpandas._libs.tslibs.strptime.array_strptime\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/tslibs/strptime.pyx:451\u001b[39m, in \u001b[36mpandas._libs.tslibs.strptime.array_strptime\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/tslibs/strptime.pyx:583\u001b[39m, in \u001b[36mpandas._libs.tslibs.strptime._parse_with_format\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mValueError\u001b[39m: time data \"20250820 24:10\" doesn't match format \"%Y%m%d %H:%M\", at position 132. You might want to try:\n    - passing `format` if your strings have a consistent format;\n    - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n    - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this."
     ]
    }
   ],
   "source": [
    "weather = pd.read_csv(\"SAIL_Amsterdam_10min_Weather_2025-08-20_to_2025-08-24.csv\")\n",
    "\n",
    "# Drop rows with invalid \"24:00\" timestamps\n",
    "weather = weather[~weather[\"DateTime\"].str.contains(\"24:00\", na=False)]\n",
    "\n",
    "# Convert DateTime to datetime objects\n",
    "weather[\"DateTime\"] = pd.to_datetime(weather[\"DateTime\"], format=\"%Y%m%d %H:%M\")\n",
    "\n",
    "# Round timestamps to the nearest 3 minutes\n",
    "weather[\"RoundedTime\"] = weather[\"DateTime\"].dt.round(\"3min\")\n",
    "\n",
    "# Drop duplicates, keeping the first entry for each 3-minute slot\n",
    "three_min_weather_data = (\n",
    "    weather.sort_values(\"DateTime\")\n",
    "           .drop_duplicates(subset=\"RoundedTime\", keep=\"first\")\n",
    "           .set_index(\"RoundedTime\")\n",
    "           .drop(columns=[\"DateTime\"])\n",
    ")\n",
    "\n",
    "# Reset index so RoundedTime becomes a column again\n",
    "three_min_weather_data = three_min_weather_data.reset_index()\n",
    "print(three_min_weather_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1c21e9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Find Flow per sensor per meter\n",
    "#Divide by 3 minutes and effective width\n",
    "\n",
    "width = sensors_location.set_index(\"sensor_id\")[\"Effectieve breedte\"].to_dict()\n",
    "\n",
    "# Divide each matching visitor column by its sensor’s width\n",
    "for col in sensors.columns:\n",
    "    if \"_\" in col:  # e.g. CMSA-GAKH-01_0\n",
    "        sensor_id = col.split(\"_\")[0]\n",
    "        if sensor_id in width:\n",
    "            sensors[col] = sensors[col] / (3*width[sensor_id])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d5c48f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Combine vessel data into 3 min bins, taking the average position of the vessel.\n",
    "vessels[\"timestamp\"] = pd.to_datetime(vessels[\"timestamp\"], utc=True, errors=\"coerce\")\n",
    "vessels[\"timestamp\"] = vessels[\"timestamp\"].dt.floor(\"3min\")\n",
    "\n",
    "vessels = (\n",
    "    vessels.groupby([\"timestamp\", \"imo-number\"], as_index=False)\n",
    "    .agg({\n",
    "        \"lat\": \"mean\",\n",
    "        \"lon\": \"mean\",\n",
    "        \"length\": \"first\"\n",
    "    })\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64459d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Combining vessel and sensor data.\n",
    "vessels[\"timestamp\"] = pd.to_datetime(vessels[\"timestamp\"], utc=True)\n",
    "sensors[\"timestamp\"] = pd.to_datetime(sensors[\"timestamp\"], utc=True)\n",
    "\n",
    "combined = sensors.merge(vessels, on=\"timestamp\", how=\"inner\")\n",
    "\n",
    "combined.head(100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f111090e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge sensor coordinates into the combined dataframe\n",
    "lat_lookup = sensors_location.set_index(\"sensor_id\")[\"lat\"].to_dict()\n",
    "lon_lookup = sensors_location.set_index(\"sensor_id\")[\"lon\"].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5287e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "def haversine(lat1, lon1, lat2, lon2):\n",
    "    R = 6371000  # Earth radius (meters)\n",
    "    lat1, lon1, lat2, lon2 = map(np.radians, [lat1, lon1, lat2, lon2])\n",
    "    dlat = lat2 - lat1\n",
    "    dlon = lon2 - lon1\n",
    "    a = np.sin(dlat/2)**2 + np.cos(lat1)*np.cos(lat2)*np.sin(dlon/2)**2\n",
    "    return 2 * R * np.arcsin(np.sqrt(a))\n",
    "\n",
    "\n",
    "# --- Compute distance for every vessel at every timestamp to every sensor ---\n",
    "for _, sensor in sensors_location.iterrows():\n",
    "    sensor_id = sensor[\"sensor_id\"]\n",
    "    s_lat = sensor[\"lat\"]\n",
    "    s_lon = sensor[\"lon\"]\n",
    "    \n",
    "    dist_col = f\"dist_{sensor_id}\"\n",
    "\n",
    "    # compute distances for all vessel positions (each timestamp)\n",
    "    combined[dist_col] = haversine(s_lat, s_lon, combined[\"lat\"], combined[\"lon\"])\n",
    "\n",
    "    # replace ≥1000 m with infinity (in place!)\n",
    "    combined[dist_col] = combined[dist_col].where(combined[dist_col] < 1000, np.inf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4be21160",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined.info()\n",
    "combined.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df48f3cc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TIL6022-25",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
