{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22a692e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Load packages\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.compose import TransformedTargetRegressor\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import TransformedTargetRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c60e7aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load pre-processed datasets\n",
    "\n",
    "vessels = pd.read_csv(\"C:/Users/Abel Arts/Downloads/Vesselposition_data_20-24Aug2025.csv\").rename(columns={\"upload-timestamp\": \"timestamp\"}).drop(columns=[\"stale_since\"])\n",
    "weather = pd.read_csv(\"SAIL_Amsterdam_10min_Weather_2025-08-20_to_2025-08-24.csv\")\n",
    "sensors_location = pd.read_csv(\"sensor-location.xlsx - Sheet1.csv\", ).rename(columns={\"Objectnummer\": \"sensor_id\"})\n",
    "sensors = pd.read_csv(\"sensordata_SAIL2025.csv\", parse_dates=[\"timestamp\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bc36263",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Mutations sensor information\n",
    "\n",
    "sensors_location[\"Effectieve breedte\"] = (\n",
    "    sensors_location[\"Effectieve breedte\"]\n",
    "    .astype(str)\n",
    "    .str.replace(\",\", \".\")\n",
    "    .astype(float)\n",
    ")\n",
    "\n",
    "\n",
    "sensors_location[[\"lat\", \"lon\"]] = (\n",
    "    sensors_location[\"Lat/Long\"]\n",
    "    .str.replace(\" \", \"\")  \n",
    "    .str.split(\",\", expand=True)\n",
    "    .astype(float)\n",
    ")\n",
    "\n",
    "sensor_prefixes = (\"CMSA-\", \"GACM-\", \"GASA-\", \"GVCV-\")\n",
    "\n",
    "width = sensors_location.set_index(\"sensor_id\")[\"Effectieve breedte\"].to_dict()\n",
    "\n",
    "for col in sensors.columns:\n",
    "    if \"_\" in col:  \n",
    "        sensor_id = col.split(\"_\")[0]\n",
    "        if sensor_id in width:\n",
    "            sensors[col] = sensors[col] / (width[sensor_id])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7598e2fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Mutations weather data\n",
    "\n",
    "# replace 24 by 00 to account for UTC datetime\n",
    "weather[\"DateTime\"] = weather[\"DateTime\"].str.replace(\" 24:\", \" 00:\", regex=False)\n",
    "\n",
    "# Convert to UTC datetime and round up for every 3 minutes\n",
    "weather[\"DateTime\"] = pd.to_datetime(weather[\"DateTime\"], format=\"%Y%m%d %H:%M\")\n",
    "weather = weather.set_index(\"DateTime\")\n",
    "weather_3min = weather.resample(\"3min\").nearest()\n",
    "weather_3min = weather_3min.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d5c48f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Mutations vessel data\n",
    "\n",
    "# Convert to UTC datetime and round up for every 3 minutes\n",
    "vessels[\"timestamp\"] = pd.to_datetime(vessels[\"timestamp\"], utc=True, errors=\"coerce\")\n",
    "vessels[\"timestamp\"] = vessels[\"timestamp\"].dt.floor(\"3min\")\n",
    "\n",
    "#Take average longitude and latitude over 3 minutes and srot by datetime\n",
    "vessels = (\n",
    "    vessels.groupby([\"timestamp\", \"imo-number\"], as_index=False)\n",
    "    .agg({\n",
    "        \"lat\": \"mean\",\n",
    "        \"lon\": \"mean\",\n",
    "        \"length\": \"first\"\n",
    "    }).dropna(subset=[\"timestamp\", \"imo-number\", \"lat\", \"lon\", \"length\"])\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64459d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "##Adding all of the weather data to the timestamps\n",
    "\n",
    "#Ensure compatitibility datetime dataset\n",
    "vessels[\"timestamp\"] = pd.to_datetime(vessels[\"timestamp\"], utc=True)\n",
    "sensors[\"timestamp\"] = pd.to_datetime(sensors[\"timestamp\"], utc=True)\n",
    "weather_3min[\"DateTime\"] = pd.to_datetime(weather_3min[\"DateTime\"], utc=True) \n",
    "\n",
    "#Merge datasets\n",
    "combined = sensors.merge(vessels, on=\"timestamp\", how=\"inner\")\n",
    "combined = combined.merge(\n",
    "    weather_3min.rename(columns={\"DateTime\": \"timestamp\"})[\n",
    "        [\"timestamp\", \"Temperature_°C\", \"Humidity_%\", \"Rain_mm\"]\n",
    "    ],\n",
    "    on=\"timestamp\",\n",
    "    how=\"left\"   # keep all rows from sensors+vessels even if weather missing\n",
    ")\n",
    "combined = combined[combined[\"length\"] > 10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5287e38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "['timestamp', 'CMSA-GAKH-01_0', 'CMSA-GAKH-01_180', 'CMSA-GAWW-11_120', 'CMSA-GAWW-11_300', 'CMSA-GAWW-12_115', 'CMSA-GAWW-12_295', 'CMSA-GAWW-13_120', 'CMSA-GAWW-13_300', 'CMSA-GAWW-14_40', 'CMSA-GAWW-14_220', 'CMSA-GAWW-15_30', 'CMSA-GAWW-15_210', 'CMSA-GAWW-16_30', 'CMSA-GAWW-16_210', 'CMSA-GAWW-17_40', 'CMSA-GAWW-17_220', 'CMSA-GAWW-19_115', 'CMSA-GAWW-19_295', 'CMSA-GAWW-20_120', 'CMSA-GAWW-20_300', 'CMSA-GAWW-21_120', 'CMSA-GAWW-21_300', 'CMSA-GAWW-23_109', 'CMSA-GAWW-23_289', 'GACM-04_50', 'GACM-04_230', 'GASA-01-A1_135', 'GASA-01-A1_315', 'GASA-01-A2_135', 'GASA-01-A2_315', 'GASA-01-B_135', 'GASA-01-B_315', 'GASA-01-C_135', 'GASA-01-C_315', 'GASA-02-01_135', 'GASA-02-01_315', 'GASA-02-02_135', 'GASA-02-02_315', 'GASA-03_105', 'GASA-03_285', 'GASA-04_135', 'GASA-04_315', 'GASA-05-O_135', 'GASA-05-O_315', 'GASA-05-W_135', 'GASA-05-W_315', 'GASA-06_95', 'GASA-06_275', 'GASA-06-B_95', 'GASA-06-B_275', 'GVCV-01_40', 'GVCV-01_220', 'GVCV-03_42', 'GVCV-03_222', 'GVCV-04_45', 'GVCV-04_225', 'GVCV-05-A_155', 'GVCV-05-A_335', 'GVCV-05-B_30', 'GVCV-05-B_210', 'GVCV-06_95', 'GVCV-06_275', 'GVCV-07_50', 'GVCV-07_230', 'GVCV-08_45', 'GVCV-08_225', 'GVCV-09_80', 'GVCV-09_260', 'GVCV-11_50', 'GVCV-11_230', 'GVCV-13_10', 'GVCV-13_190', 'GVCV-14_90', 'GVCV-14_270', 'hour', 'minute', 'day', 'month', 'weekday', 'is_weekend', 'imo-number', 'lat', 'lon', 'length', 'Temperature_°C', 'Humidity_%', 'Rain_mm', 'dist_CMSA-GAKH-01', 'dist_CMSA-GAWW-11', 'dist_CMSA-GAWW-12', 'dist_CMSA-GAWW-13', 'dist_CMSA-GAWW-14', 'dist_CMSA-GAWW-15', 'dist_CMSA-GAWW-16', 'dist_CMSA-GAWW-17', 'dist_CMSA-GAWW-19', 'dist_CMSA-GAWW-20', 'dist_CMSA-GAWW-21', 'dist_CMSA-GAWW-23', 'dist_GACM-04', 'dist_GVCV-01', 'dist_GVCV-03', 'dist_GVCV-04', 'dist_GVCV-05-A', 'dist_GVCV-05-B', 'dist_GVCV-06', 'dist_GVCV-07', 'dist_GVCV-08', 'dist_GVCV-09', 'dist_GVCV-11', 'dist_GVCV-13', 'dist_GVCV-14', 'dist_GASA-06', 'dist_GASA-01-A1', 'dist_GASA-01-A2', 'dist_GASA-01-B', 'dist_GASA-01-C', 'dist_GASA-02-01', 'dist_GASA-02-02', 'dist_GASA-03', 'dist_GASA-04', 'dist_GASA-05-O', 'dist_GASA-05-W']\n",
      "                  timestamp  CMSA-GAKH-01_0  CMSA-GAKH-01_180  \\\n",
      "0 2025-08-20 06:27:00+00:00        0.000000          0.298507   \n",
      "1 2025-08-20 06:27:00+00:00        0.000000          0.298507   \n",
      "2 2025-08-20 06:27:00+00:00        0.000000          0.298507   \n",
      "3 2025-08-20 06:27:00+00:00        0.000000          0.298507   \n",
      "5 2025-08-20 06:30:00+00:00        0.597015          0.447761   \n",
      "\n",
      "   CMSA-GAWW-11_120  CMSA-GAWW-11_300  CMSA-GAWW-12_115  CMSA-GAWW-12_295  \\\n",
      "0          1.176471          1.764706          1.923077          0.769231   \n",
      "1          1.176471          1.764706          1.923077          0.769231   \n",
      "2          1.176471          1.764706          1.923077          0.769231   \n",
      "3          1.176471          1.764706          1.923077          0.769231   \n",
      "5          1.764706          1.176471          2.307692          0.769231   \n",
      "\n",
      "   CMSA-GAWW-13_120  CMSA-GAWW-13_300  CMSA-GAWW-14_40  ...  dist_GASA-01-A1  \\\n",
      "0          0.454545          0.000000         0.555556  ...     94455.111334   \n",
      "1          0.454545          0.000000         0.555556  ...    148716.414231   \n",
      "2          0.454545          0.000000         0.555556  ...    105762.038057   \n",
      "3          0.454545          0.000000         0.555556  ...     75214.264490   \n",
      "5          0.454545          0.454545         1.666667  ...      9538.347989   \n",
      "\n",
      "   dist_GASA-01-A2  dist_GASA-01-B  dist_GASA-01-C  dist_GASA-02-01  \\\n",
      "0     94451.987036    94425.994141    94419.114868     94659.426239   \n",
      "1    148720.189149   148735.620728   148743.362521    148825.404631   \n",
      "2    105759.096469   105733.118968   105726.588367    105987.764748   \n",
      "3     75210.573420    75186.047258    75178.140481     75318.563506   \n",
      "5      9537.983204     9519.957516     9518.639039      9895.770438   \n",
      "\n",
      "   dist_GASA-02-02   dist_GASA-03   dist_GASA-04  dist_GASA-05-O  \\\n",
      "0     94653.192625   95015.520004   94517.740136    96024.703788   \n",
      "1    148832.949948  148815.347353  149021.146446   147439.618095   \n",
      "2    105981.895483  106362.086765  105856.615913   107298.248115   \n",
      "3     75311.193281   75578.957182   75141.726531    76829.585221   \n",
      "5      9895.081566   10329.117229    9904.608793    10398.551638   \n",
      "\n",
      "   dist_GASA-05-W  \n",
      "0    95992.249930  \n",
      "1   147422.815060  \n",
      "2   107262.453732  \n",
      "3    76812.584572  \n",
      "5    10343.722391  \n",
      "\n",
      "[5 rows x 124 columns]\n"
     ]
    }
   ],
   "source": [
    "#Calculate distance sensors to vessels every three minutes\n",
    "\"This looks at the amount of >100 m vessels that are inside a radius of a 1000 m to the sensor (the closer they are the heavier they are weighted)\"\n",
    "\n",
    "# Merge sensor coordinates into the combined dataframe\n",
    "lat_lookup = sensors_location.set_index(\"sensor_id\")[\"lat\"].to_dict()\n",
    "lon_lookup = sensors_location.set_index(\"sensor_id\")[\"lon\"].to_dict()\n",
    "\n",
    "#Haversine function for accurate distance calculation\n",
    "def haversine(lat1, lon1, lat2, lon2):\n",
    "    R = 6371000  # Earth radius (meters)\n",
    "    lat1, lon1, lat2, lon2 = map(np.radians, [lat1, lon1, lat2, lon2])\n",
    "    dlat = lat2 - lat1\n",
    "    dlon = lon2 - lon1\n",
    "    a = np.sin(dlat/2)**2 + np.cos(lat1)*np.cos(lat2)*np.sin(dlon/2)**2\n",
    "    return 2 * R * np.arcsin(np.sqrt(a))\n",
    "\n",
    "\n",
    "# Compute distance for every vessel at every timestamp to every sensor \n",
    "for _, sensor in sensors_location.iterrows():\n",
    "    sensor_id = sensor[\"sensor_id\"]\n",
    "    s_lat = sensor[\"lat\"]\n",
    "    s_lon = sensor[\"lon\"]\n",
    "    \n",
    "    dist_col = f\"dist_{sensor_id}\" \n",
    "    combined[dist_col] = haversine(s_lat, s_lon, combined[\"lat\"], combined[\"lon\"])\n",
    "\n",
    "print(combined.isna().sum().tolist())\n",
    "print(combined.columns.tolist())\n",
    "print(combined.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "999c89ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# --- Cap all distances at 1000 m (no influence beyond that) ---\n",
    "for col in [c for c in combined.columns if c.startswith(\"dist_\")]:\n",
    "    combined[col] = combined[col].clip(0, 1000)\n",
    "\n",
    "# --- Weighted aggregation per timestamp ---\n",
    "agg_rows = []\n",
    "for ts, group in combined.groupby(\"timestamp\"):\n",
    "    # Compute inverse-distance weights per vessel\n",
    "    dist_cols = [c for c in group.columns if c.startswith(\"dist_\")]\n",
    "    weights = 1 / (group[dist_cols].clip(lower=1))  # avoid division by zero\n",
    "\n",
    "    temp = {\n",
    "        \"timestamp\": ts,\n",
    "        # Copy weather data directly (same for all vessels at timestamp)\n",
    "        \"Temperature_°C\": group[\"Temperature_°C\"].iloc[0],\n",
    "        \"Humidity_%\": group[\"Humidity_%\"].iloc[0],\n",
    "        \"Rain_mm\": group[\"Rain_mm\"].iloc[0],\n",
    "    }\n",
    "\n",
    "    # Weighted vessel length (heavier = more influence)\n",
    "    temp[\"length_weighted\"] = np.average(group[\"length\"], weights=weights.mean(axis=1))\n",
    "\n",
    "    # Weighted mean distances (closer vessels have more influence)\n",
    "    for col in dist_cols:\n",
    "        temp[f\"{col}_weighted\"] = np.average(group[col], weights=1 / (group[col] + 1))\n",
    "\n",
    "    # Sensor targets (same for all vessels per timestamp)\n",
    "    for target in [c for c in combined.columns if c.startswith(sensor_prefixes)]:\n",
    "        temp[target] = group[target].iloc[0]\n",
    "\n",
    "    agg_rows.append(temp)\n",
    "\n",
    "agg_df = pd.DataFrame(agg_rows)\n",
    "\n",
    "# --- Clean data ---\n",
    "agg_df = agg_df.dropna()\n",
    "\n",
    "# Define the split timestamp (the moment where train ends and test begins)\n",
    "split_time = pd.Timestamp(\"2025-08-24 00:00:00+02:00\")\n",
    "\n",
    "# Split the dataset\n",
    "train_data = agg_df[agg_df[\"timestamp\"] < split_time]\n",
    "test_data  = agg_df[agg_df[\"timestamp\"] >= split_time]\n",
    "\n",
    "# --- Define predictors and targets ---\n",
    "feature_cols = (\n",
    "    [\"Temperature_°C\", \"Humidity_%\", \"Rain_mm\", \"length_weighted\"]\n",
    "    + [c for c in agg_df.columns if c.startswith(\"dist_\")]\n",
    ")\n",
    "target_cols = [c for c in agg_df.columns if c.startswith(sensor_prefixes)]\n",
    "\n",
    "# --- Prepare matrices ---\n",
    "X_train = train_data[feature_cols].values\n",
    "X_test  = test_data[feature_cols].values\n",
    "y_train = train_data[target_cols].values\n",
    "y_test  = test_data[target_cols].values\n",
    "\n",
    "# --- Define Ridge regression pipeline ---\n",
    "ridge_pipeline = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"ridge\", Ridge(alpha=3.0, random_state=0))\n",
    "])\n",
    "\n",
    "# --- Wrap in log/expm1 transformation for positive outputs ---\n",
    "model = TransformedTargetRegressor(\n",
    "    regressor=ridge_pipeline,\n",
    "    func=np.log1p,\n",
    "    inverse_func=np.expm1\n",
    ")\n",
    "\n",
    "# --- Train model ---\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# --- Predict ---\n",
    "preds = model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c89c5c96",
   "metadata": {},
   "outputs": [],
   "source": [
    "#postprocessing\n",
    "preds = np.clip(preds, 0, None)\n",
    "preds = np.round(preds, 2)\n",
    "\n",
    "\n",
    "pred_df = pd.DataFrame(preds, columns=target_cols)\n",
    "pred_df.insert(0, \"timestamp\", test_data[\"timestamp\"].values)\n",
    "pred_df.to_csv(\"predicted_sensor_values_3min.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da55edf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Visuals\n",
    "\n",
    "# Compare to your test data (after inverse_transform)\n",
    "sample_preds = model.predict(X_test[:5])\n",
    "print(\"Sample predictions:\", sample_preds)\n",
    "print(\"Corresponding actuals:\", y_test[:5])\n",
    "\n",
    "# Evaluate performance \n",
    "mse = mean_squared_error(y_test, preds)\n",
    "rmse = np.sqrt(mse)\n",
    "mae = mean_absolute_error(y_test, preds)\n",
    "\n",
    "print(\"✅ Ridge Model Results\")\n",
    "print(f\"MAE:  {mae:.2f}\")\n",
    "print(f\"RMSE: {rmse:.2f}\")\n",
    "\n",
    "# Optional: Compare average predictions ---\n",
    "print(\"\\n--- Mean Comparison ---\")\n",
    "print(f\"Train target mean: {y_train.mean():.2f}\")\n",
    "print(f\"Test  target mean: {y_test.mean():.2f}\")\n",
    "print(f\"Pred  mean:        {preds.mean():.2f}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d54b947",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Visualize how much of the data is used for training vs prediction ---\n",
    "sizes = [len(train_data), len(test_data)]\n",
    "labels = ['Training data (20/08 - 23/08)', 'Prediction data (24/08)']\n",
    "\n",
    "plt.bar(labels, sizes, color=['skyblue', 'lightcoral'])\n",
    "plt.title('Data used for model training vs prediction')\n",
    "plt.ylabel('Number of timestamps')\n",
    "plt.xticks(rotation=10)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9c2edb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features = [\"Humidity_%\", \"length_weighted\", \"Temperature_°C\"]\n",
    "filtered = (\n",
    "    coef_df[coef_df[\"feature\"].isin(selected_features)]\n",
    "    .sort_values(\"importance\", ascending=False)\n",
    "    .copy()\n",
    ")\n",
    "filtered[\"clean_name\"] = (\n",
    "    filtered[\"feature\"]\n",
    "    .replace({\n",
    "        \"length_weighted\": \"Proximity to ships\"\n",
    "    })\n",
    "    .str.replace(\"_\", \" \")\n",
    "    .str.replace(\"%\", \" %\")\n",
    ")\n",
    "\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.barh(filtered[\"clean_name\"], filtered[\"importance\"], color=\"skyblue\")\n",
    "plt.gca().invert_yaxis()\n",
    "plt.xlabel(\"Coefficient Magnitude (Importance)\")\n",
    "plt.title(\"Selected Feature Importances (Ridge Regression)\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7f71018",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Visualization ---\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.scatter(y_test.flatten(), preds.flatten(), alpha=0.6)\n",
    "plt.xlabel(\"Actual visitors\")\n",
    "plt.ylabel(\"Predicted visitors\")\n",
    "plt.title(\"Ridge Regression: Predicted vs Actual\")\n",
    "plt.grid(True)\n",
    "plt.plot([y_test.min(), y_test.max()],\n",
    "         [y_test.min(), y_test.max()],\n",
    "         'r--', lw=2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cb382aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- Residual plot ---\n",
    "plt.figure(figsize=(8,5))\n",
    "residuals = y_test.flatten() - preds.flatten()\n",
    "plt.hist(residuals, bins=30, color='skyblue', edgecolor='k')\n",
    "plt.title(\"Residuals Distribution (Actual - Predicted)\")\n",
    "plt.xlabel(\"Error\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a821e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Filter and clean feature names ---\n",
    "excluded = [\"Humidity_%\", \"Temperature_°C\", \"length_weighted\", \"Rain_mm\"]\n",
    "filtered = coef_df[~coef_df[\"feature\"].isin(excluded)].copy()\n",
    "\n",
    "# Compute absolute importance and sort descending\n",
    "filtered[\"abs_importance\"] = filtered[\"importance\"].abs()\n",
    "filtered = filtered.sort_values(\"abs_importance\", ascending=False)\n",
    "\n",
    "# Clean up feature names\n",
    "filtered[\"clean_name\"] = (\n",
    "    filtered[\"feature\"]\n",
    "    .str.replace(\"^dist_\", \"\", regex=True)\n",
    "    .str.replace(\"_weighted$\", \"\", regex=True)\n",
    ")\n",
    "\n",
    "# Prepare colors\n",
    "colors = plt.cm.plasma(np.linspace(0, 1, len(filtered)))\n",
    "\n",
    "# --- Plot ---\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.bar(filtered[\"clean_name\"], filtered[\"abs_importance\"], color=colors)\n",
    "plt.xticks(rotation=90)\n",
    "plt.ylabel(\"Coefficient Magnitude (Importance)\")\n",
    "plt.xlabel(\"Sensors\")\n",
    "plt.title(\"Sensors most effected by nearby vessels\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4925478",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "33ce1484a08e461ced66908137b95326b7f2bfea3b661181fcc1641c97ce2a7b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
